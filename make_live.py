import asyncio
import httpx
import re
import os

# ================= é…ç½®åŒº =================
USER_CONFIG = {
    "github_user": "vreace-afk", 
    "repo_name": "live",         
}
# ==========================================

# æ›´æ¢ä¸€ç»„è¶…å¼ºçš„ä¿åº•æº (åŒ…å« CCTV1, 6, 13 å’Œ æ¹–å—å«è§†)
BASE_CHANNELS = """
#EXTINF:-1 group-title="å¤®è§†é¢‘é“" tvg-name="CCTV-1",CCTV-1 ç»¼åˆ
http://39.134.115.163:8080/PLTV/88888888/224/3221225618/index.m3u8
#EXTINF:-1 group-title="å¤®è§†é¢‘é“" tvg-name="CCTV-6",CCTV-6 ç”µå½±
http://39.134.115.163:8080/PLTV/88888888/224/3221225633/index.m3u8
#EXTINF:-1 group-title="å¤®è§†é¢‘é“" tvg-name="CCTV-13",CCTV-13 æ–°é—»
http://39.134.115.163:8080/PLTV/88888888/224/3221225579/index.m3u8
#EXTINF:-1 group-title="åœ°æ–¹å«è§†" tvg-name="æ¹–å—å«è§†",æ¹–å—å«è§†
http://39.134.65.162/migu/621510489/1.m3u8
"""

EXTERNAL_M3U_URLS = [
    "https://ghp.ci/https://raw.githubusercontent.com/fanmingming/live/main/tv/m3u/ipv6.m3u",
    "https://ghp.ci/https://raw.githubusercontent.com/YanG-1989/m3u/main/Gather.m3u",
    "https://ghp.ci/https://raw.githubusercontent.com/Guover/IPTV/master/CH.m3u",
    "https://ghp.ci/https://raw.githubusercontent.com/ssili126/tv/main/itvlist.m3u",
    "https://ghp.ci/https://raw.githubusercontent.com/YueChan/Live/main/IPTV.m3u",
    "https://ghp.ci/https://raw.githubusercontent.com/v_v/v/master/v.m3u" # æš´åŠ›æœç´¢æº
]

async def fetch_external_sources():
    extra_channels = []
    rules = [
        (r".*?(CCTV|å¤®è§†|cctv|4K|8K).*", "å¤®è§†é¢‘é“"),
        (r".*?å«è§†", "åœ°æ–¹å«è§†"),
        (r".*?(ç”µå½±|CHC|HBO|å½±é™¢|å‰§åœº|å½±è§†|åŠ¨ä½œ|å–œå‰§).*", "ç”µå½±é¢‘é“"),
        (r".*?(ä½“è‚²|äº”æ˜Ÿ|åŠ²çˆ†|é«˜å°”å¤«|è¶³çƒ|NBA|èµ›è½¦).*", "ä½“è‚²ä¸“åŒº")
    ]
    
    # è¿›ä¸€æ­¥æ”¾å®½è¶…æ—¶å’Œé™åˆ¶
    async with httpx.AsyncClient(timeout=45.0, follow_redirects=True, verify=False) as client:
        for url in EXTERNAL_M3U_URLS:
            try:
                print(f"æ­£åœ¨å…¨ç½‘æœç´¢: {url}")
                resp = await client.get(url)
                if resp.status_code == 200:
                    content = resp.text
                    for pattern_str, group_name in rules:
                        regex = re.compile(rf'(#EXTINF:.*?,({pattern_str}).*?\n(http.*?))', re.IGNORECASE)
                        matches = regex.findall(content)
                        for _, name, link in matches:
                            extra_channels.append(f'#EXTINF:-1 group-title="{group_name}" tvg-name="{name.strip()}",{name.strip()}\n{link.strip()}')
            except: continue
    return list({line.split(',')[1]: line for line in extra_channels}.values())

def update_readme(count):
    cdn_url = f"https://jsd.onmicrosoft.cn/gh/{USER_CONFIG['github_user']}/{USER_CONFIG['repo_name']}/cctv.m3u"
    content = f"# ğŸ“º æˆ‘çš„ç§äººç›´æ’­æº\n\n## ğŸ”— è®¢é˜…åœ°å€ (é•¿æŒ‰å¤åˆ¶)\n`{cdn_url}`\n\n## ğŸ“Š çŠ¶æ€æ±‡æ€»\n- **é¢‘é“æ€»æ•°**: {count}\n- **æœ€åæ›´æ–°**: {os.popen('date').read().strip()}\n"
    with open("README.md", "w", encoding="utf-8") as f:
        f.write(content)

async def main():
    ext_res = await fetch_external_sources()
    final_list = BASE_CHANNELS.strip().split('\n') + ext_res
    
    with open("cctv.m3u", "w", encoding="utf-8") as f:
        f.write("#EXTM3U\n" + "\n".join(all_lines := [l for l in final_list if l.strip()]))
    
    count = len([l for l in all_lines if "#EXTINF" in l])
    update_readme(count)
    print(f"âœ… æ•è·æˆåŠŸï¼æ€»è®¡ {count} ä¸ªé¢‘é“")

if __name__ == "__main__":
    asyncio.run(main())
